# ğŸ“Š vid2slides (M1-Optimized)

`vid2slides` is a tool to **extract slides from lecture or meeting recordings**.  
This version is optimized for **Apple Silicon (M1/M2)** and replaces `decord` with **ffmpeg + OpenCV**.  
It also uses **pytesseract** for OCR and **tqdm** for progress tracking.

---

## ğŸ“‚ Directory Structure


Your project directory should look like this:

vid2slides-main/
â”œâ”€â”€ demo/                         
â”œâ”€â”€ models/
â”‚   â””â”€â”€ haarcascade_frontalface_default.xml
â”œâ”€â”€ vid2slides/
â”‚   â”œâ”€â”€ slides2chapters.py
â”‚   â”œâ”€â”€ slides2gif.py
â”‚   â”œâ”€â”€ slides2pdf.py
â”‚   â”œâ”€â”€ vid2slides.py
â”‚   â””â”€â”€ vid2slides_m1.py
â”œâ”€â”€ environment_m1.yml
â”œâ”€â”€ my_video.mp4
â”œâ”€â”€ output.json
â”œâ”€â”€ README.md / come.md




---

## ğŸ›  Technologies Used

- **ffmpeg** â†’ Extracts thumbnails & high-resolution frames from video.  
- **OpenCV** â†’ Handles image operations (grayscale, face detection, slide difference, cropping).  
- **Haar Cascade Classifier** â†’ Detects faces to avoid false slide detections.  
- **pytesseract (Tesseract OCR)** â†’ Extracts text (titles) from slides.  
- **tqdm** â†’ Displays progress bars during long operations.  
- **Python 3.10+** â†’ Main scripting language.  

---

## âš™ï¸ How the Project Works

1. **Thumbnail Extraction (ffmpeg)**  
   - Extracts low-res thumbnails every `thumb_interval` seconds.  
   - Example: 5h lecture â†’ ~10,000 thumbnails.

2. **Face Detection (OpenCV Haar Cascade)**  
   - Detects faces in thumbnails to avoid classifying PiP (Picture-in-Picture) speaker frames as slides.

3. **Slide Change Detection**  
   - Computes frame-to-frame difference (SSE).  
   - Marks change points when the slide content changes significantly.

4. **Segment Building**  
   - Groups frames between change points into slide segments.  
   - Picks one representative frame per segment.

5. **High-Res Frame Extraction (ffmpeg)**  
   - Extracts clean high-resolution frames for the representative slides.

6. **Crop Detection (OpenCV)**  
   - Finds the bounding box of the slide region.  
   - Ensures OCR only processes the actual slide content.

7. **OCR (pytesseract)**  
   - Reads text from slides.  
   - Extracts likely **titles** (usually the top-most text).

8. **JSON Output**  
   - Stores structured data: slide start/end times, titles, image paths, crop info.  
   - Used by converters (`slides2pdf.py`, `slides2gif.py`, `slides2chapters.py`).

---

## ğŸš€ Installation

1. Clone the repo:
```bash
git clone https://github.com/YOURNAME/vid2slides.git
cd vid2slides-main
Create environment:

bash

conda env create -f environment_m1.yml
conda activate vid2slides-m1
Install tqdm (progress bar):

bash

pip install tqdm
Ensure ffmpeg & Tesseract are installed:

bash

ffmpeg -version
tesseract --version
ğŸ›  Usage
1ï¸âƒ£ Extract slides to JSON
bash

python vid2slides/vid2slides_m1.py my_video.mp4 output.json
Input: my_video.mp4

Output: output.json with slide data.

2ï¸âƒ£ Convert JSON â†’ PDF
bash

python vid2slides/slides2pdf.py output.json slides.pdf
Output: slides.pdf (OCR-enabled, searchable).

3ï¸âƒ£ Convert JSON â†’ GIF
bash

python vid2slides/slides2gif.py output.json slides.gif
Output: slides.gif with slide transitions.

4ï¸âƒ£ Convert JSON â†’ YouTube Chapters
bash

python vid2slides/slides2chapters.py output.json > chapters.txt
Output: chapters.txt (ready to paste into YouTube description).

ğŸ“Š Example Outputs
GIF of slides


OCR-enabled PDF
Sample PDF

YouTube Chapters

makefile
Copy code
00:00 Start
00:01:12 Motivation
00:02:16 Inferring Generative Models from Data
00:04:14 Increasing Computational Capacity
...
â± Performance
Thumbnail extraction: ~30â€“40Ã— faster than real-time on M1.

Face detection + slide change detection: a few minutes for ~10k thumbnails.

OCR: ~0.5â€“1.5s per slide (e.g. 300 slides â†’ ~10â€“15 min).

Total for a 5h lecture: ~2â€“4 hours.



---






